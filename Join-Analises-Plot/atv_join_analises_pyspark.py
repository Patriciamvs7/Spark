# -*- coding: utf-8 -*-
"""atv_join_analises_pyspark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11cYbv-_8eW5oTPeY42Vvy2nQIDe6kgtf
"""

!pip install pyspark

from pyspark.sql import SparkSession
import pyspark.sql.functions as F
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

#CONFIGURAR A SESSÃO SPARK
spark = (SparkSession.builder
                     .master('local')
                     .appName('Analise_MBA')
                     .config('spark.ui.port', '4050')
                     .getOrCreate())

spark

df_aisles = (spark.read.format('csv')
                       .option('delimiter', ',')
                       .option('header', 'true')
                       .option('inferschema', 'true')
                       .load('/content/drive/MyDrive/Join/aisles.csv'))

df_products_prior = (spark.read.format('csv')
                       .option('delimiter', ',')
                       .option('header', 'true')
                       .option('inferschema', 'true')
                       .load('/content/drive/MyDrive/Join/order_products__prior.csv'))

df_products = (spark.read.format('csv')
                       .option('delimiter', ',')
                       .option('header', 'true')
                       .option('inferschema', 'true')
                       .load('/content/drive/MyDrive/Join/products.csv'))

df_departments = (spark.read.format('csv')
                       .option('delimiter', ',')
                       .option('header', 'true')
                       .option('inferschema', 'true')
                       .load('/content/drive/MyDrive/Join/departments.csv'))

df_orders = (spark.read.format('csv')
                       .option('delimiter', ',')
                       .option('header', 'true')
                       .option('inferschema', 'true')
                       .load('/content/drive/MyDrive/Join/orders.csv'))

df_departments.show(3)

df_departments.count()

df_departments.show()

df_orders.count()

df_orders.show(3)

df_products_prior.show(3)

df_aisles.show(5, truncate=False)

df_products.show(5, truncate=False)

df_backup = df_products_prior

df_products_prior = df_products_prior.dropna(how='any')

df_products_prior.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df_products_prior.columns]).show()

df_products_prior.printSchema()

df_orders.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df_orders.columns]).show()

df_products_prior = df_backup

df_products_prior = df_products_prior.withColumn('pedido_anteriormente', F.regexp_replace(F.col('reordered'), '1', "Sim"))

df_products_prior = df_products_prior.withColumn('pedido_anteriormente', F.regexp_replace(F.col('pedido_anteriormente'), '0', "Nao"))

df_products_prior.show()

# 1º JOIN - df_order_product_prior com order
df_join = df_products_prior.join(df_orders, on=['order_id'], how='left')

df_join.select('*').orderBy(F.col('order_id').desc()).show(5)

df_join.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df_join.columns]).show()

df_products.show(5)

# 2º JOIN df_joincom product
df_join = df_join.join(df_products, on=['product_id'], how='left')

# 3º JOIN df_join com aisles
df_join = df_join.join(df_aisles, on=['aisle_id'], how='left')

#4º JOIN df_join com department
df_join = df_join.join(df_departments, on=['department_id'], how='left')

df_join.printSchema()

df_join.show()

#EXISTEM VALORES NULOS NOS DATAFRAMES?
df_join.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df_join.columns]).show()

df_products_prior.show(3)

df_products.show(3)

df_aisles.show(3)

df_orders.show(3)

#DROPAR O ÚNICO REGISTRO QUE POSSUI DADOS NULOS EM AISLE E DEPARTMENT
df_join = df_join.dropna(how='any', subset='aisle')
df_join = df_join.dropna(how='any', subset='department')

#CALCULAR O PERCENTUAL DE VALORES AUSENTES NA COLUNA days_since_prior_order
media = (df_join.filter(F.col('days_since_prior_order').isNull() | F.isnan(F.col('days_since_prior_order'))).count() / df_join.select('days_since_prior_order').count() * 100)

print(media)

df = df_join

df.show()

"""1) QUAL O NÚMERO DE PEDIDOS MAIS FREQUENTES ENTRE OS CLIENTES?"""

df_orders.show(5)

#              QUAL O NÚMERO DE PEDIDOS MAIS FREQUENTES ENTRE OS CLIENTES?
qtd_compras_usuarios = df_orders.groupBy(F.col('user_id')).agg(F.count('order_number').alias('qtd_pedidos')).orderBy(F.col('user_id').asc())

qtd_compras_usuarios.show(2)

qtd_compras_usuarios.groupBy('qtd_pedidos').agg(F.count('qtd_pedidos').alias('frequencia')).orderBy(F.col('frequencia').desc()).show(2)

df_orders.groupBy(F.col('order_number')).agg(F.count('order_number').alias('n de pedidos')).orderBy(F.col('n de pedidos').desc()).show()

#QUANTIDADE DE PEDIDOS QUE MAIS APARECERAM
df_orders.agg(F.mode('order_number').alias('moda')).show()

"""2) QUAL O DIA DA SEMANA TEM O MAIOR NÚMERO DE PEDIDOS?
   - Verifique também a quantidade de pedidos em cada dia da semana
"""

df_join.show(1)

df_pedidos = df_orders.groupBy(F.col('order_dow')).agg(F.count('order_dow').alias('qtd_pedidos')).orderBy(F.col('qtd_pedidos').desc())

#dias_semana - CRIAR UMA LISTA COM DIAS DA SEMANA (0-6)
#total_pedidos - LISTA DA QUANTIDADE DE PEDIDOS POR DIA DA SEMANA
dias_semana = list(range(0, 7))
total_pedidos = []

for i in range(7):
  total_pedidos.append(df_orders.filter(F.col('order_dow') == i).count())
'''
total_pedidos = [df_orders.filter(F.col('order_dow') == 0).count(),
                 df_orders.filter(F.col('order_dow') == 1).count(),
                 df_orders.filter(F.col('order_dow') == 2).count(),
                 df_orders.filter(F.col('order_dow') == 3).count(),
                 df_orders.filter(F.col('order_dow') == 4).count(),
                 df_orders.filter(F.col('order_dow') == 5).count(),
                 df_orders.filter(F.col('order_dow') == 6).count()]
'''
print(total_pedidos)

# Plot
plt.figure(figsize = (10,5))
plt.bar(dias_semana,total_pedidos, color = 'slateblue')
plt.xlabel('Dia da Semana', fontsize = 14, fontweight = 'bold')
plt.ylabel('Frequência', fontsize = 14, fontweight = 'bold')
plt.xticks(dias_semana,['Domingo', 'Segunda', 'Terça', 'Quarta', 'Quinta', 'Sexta', 'Sábado'], rotation = 'vertical')
plt.show()

"""3) QUAL HORA DO DIA TEM O MAIOR NÚMERO DE PEDIDOS?"""

df_orders.groupBy(F.col('order_hour_of_day')).agg(F.count('order_hour_of_day').alias('qtd_pedidos')).orderBy(F.col('qtd_pedidos').desc()).show()

"""3) QUAL HORA DO DIA TEM O MAIOR NÚMERO DE PEDIDOS?"""

lista_horas = list(range(0, 24))
qtd_pedidos = []

for i in range(24):
  qtd_pedidos.append(df_orders.filter(F.col('order_hour_of_day') == i).count())

# Plot
plt.figure(figsize = (20,5))
plt.bar(lista_horas,qtd_pedidos,color = 'forestgreen')
plt.xticks(np.arange(0,24,1))
plt.xlabel('Hora do Dia', fontsize = 14, fontweight = 'bold')
plt.ylabel('Frequência', fontsize = 14, fontweight = 'bold')
plt.show()

"""4) QUAL O DEPARTAMENTO TEM O MAIOR NÚMERO DE PEDIDOS?"""

df_departments.show(10)

df_prod_dep = df_products.join(df_departments, on=['department_id'], how='left')

df_prod_dep.show()

#4) QUAL O DEPARTAMENTO TEM O MAIOR NÚMERO DE PEDIDOS?
#df_orders.groupBy(F.col('order_hour_of_day')).agg(F.count('order_hour_of_day').alias('qtd_pedidos')).orderBy(F.col('qtd_pedidos').desc()).show()
df_prod_dep.groupBy(F.col('department_id')).agg(F.count('product_id').alias('qtd_prod')).orderBy(F.col('qtd_prod').desc()).show()

"""5 - QUAIS OS 20 PRINCIPAIS CORREDORES POR FREQUÊNCIA DE PEDIDOS?"""

df_aisles.show(5)

df_orders.show(1)

#qtd_compras_usuarios.groupBy('qtd_pedidos').
#agg(F.count('qtd_pedidos').alias('frequencia')).orderBy(F.col('frequencia').desc()).show(2)
df_join.groupBy( F.col('aisle')).agg(F.count('order_number').alias('n de pedidos')).orderBy(F.col('n de pedidos').desc()).show(truncate=False)

df_join.agg(F.mode('aisle').alias('moda')).show()

"""6 - QUAIS OS 20 PRINCIPAIS PRODUTOS POR FREQUÊNCIA DE PEDIDOS?"""

df_products_prior.show(3)

df_products.show(3)

df_join.groupBy(F.col('product_name')).agg(F.count('order_number').alias('qtd de pedidos')).orderBy(F.col('qtd de pedidos').desc()).show(truncate=False)

"""7 - ANÁLISE DE NOVOS PEDIDOS SEMELHANTES A PEDIDOS ANTERIORES (reorder)"""

df_products_prior.show(2)

df_join.groupBy(F.col('product_name'), F.col('reordered')).agg(F.count('order_number').alias('qtd de pedidos')).orderBy(F.col('qtd de pedidos').desc()).show(truncate=False)

df_join.groupBy(F.col('pedido_anteriormente')).agg(F.count('order_number').alias('qtd de pedidos')).orderBy(F.col('qtd de pedidos').desc()).show(truncate=False)

df_join.groupBy(F.col('reordered')).agg(F.count('order_number').alias('qtd de pedidos')).orderBy(F.col('qtd de pedidos').desc()).show(truncate=False)

"""7 - ANÁLISE DE RECOMPRA(reorder) POR DEPARTAMENTO AO LONGO DO TEMPO"""

df_join.printSchema()

df_orders.groupBy(F.col('order_dow')).sum('order_number').orderBy(F.col('order_dow')).show()
#F.sum('order_number').orderBy(F.col('order_number')).desc().show()

df_recompra = df_join.groupBy(F.col('department'), F.col('order_dow'), F.col('order_hour_of_day')).agg(F.sum('reordered').alias("quantidade de recompra")).orderBy(F.col('quantidade de recompra').desc())

df_recompra.show(3)

df_recompra.withColumn('dias_semana', F.regexp_replace(F.col('order_dow'), '0', 'Domingo')

"""8 - ANÁLISE DE REORDER E PEDIDOS - pessoas que compram determinado produto e compram novamente.

9) Análise de Reorder por Corredor

10 - ANÁLISE DE REORDER POR CORREDOR - Total de Reorder por Corredor de Produtos Conseguimos ver os corredores que menos tiverem novos pedidos, e aqueles que tiveram mais novos pedidos.
"""